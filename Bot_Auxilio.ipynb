{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f46a34",
   "metadata": {},
   "source": [
    "# Scraping Portal da Transparência\n",
    "\n",
    "\n",
    "### Autor: Wesley Wilson\n",
    "\n",
    "<b>Informações do Mês 07/2022 (Última base disponibilizada pelo Governo Federal)</b><br>\n",
    "\n",
    "### Inicio\n",
    " - Esse crawler retorna os dados do portal da Transparência, selecionando a última base de dados disponível.\n",
    " - Projeto desenvolvido em Python 3.10, foram utlizadas as bibliotecas selenium e BeautifulSoup, urllib, datetime, sqlalchemy e pandas além das nativas do python, os, time, datetime e csv.\n",
    " - As libs necessárias para o projeto encontram-se no requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed642ff",
   "metadata": {},
   "source": [
    "## Recursos utilizados no desenvolvimento:\n",
    "\n",
    "- jupyter-lab\n",
    "- python 3.10.5\n",
    "- arquivo example_psql.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fe049",
   "metadata": {},
   "source": [
    "### Importando Libs\n",
    "\n",
    "* Importante: Se faz necessário o download do chromedriver de acordo com sua versão do navegador. \n",
    "* Download disponível em: https://chromedriver.chromium.org/downloads\n",
    "* Foi usado o chromedriver da versão 102.0.5005.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a436e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import urllib.request as urllib_request\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib import request\n",
    "from urllib.error import URLError, HTTPError\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from zipfile import ZipFile\n",
    "import example_psql as creds ##### Arquivo com dados usuario conexao Dbeaver\n",
    "import numpy as np\n",
    "from clint.textui import progress\n",
    "import sys\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd090662",
   "metadata": {},
   "source": [
    "#### Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c118959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WESLEYWILSONFERNANDE\\AppData\\Local\\Temp\\ipykernel_6576\\1265152398.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n",
      "C:\\Users\\WESLEYWILSONFERNANDE\\AppData\\Local\\Temp\\ipykernel_6576\\1265152398.py:12: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acessando Portal da Transparencia...\n",
      "Selecionando o benefício...\n",
      "Coletando dados...\n",
      "Download da base...\n",
      "Download concluído. Extraindo...\n",
      "Reading CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WESLEYWILSONFERNANDE\\AppData\\Local\\Temp\\ipykernel_6576\\1265152398.py:87: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file_name+\"_AuxilioBrasil.csv\", encoding='iso-8859-1',\n",
      "C:\\Users\\WESLEYWILSONFERNANDE\\AppData\\Local\\Temp\\ipykernel_6576\\1265152398.py:87: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(file_name+\"_AuxilioBrasil.csv\", encoding='iso-8859-1',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export data frame to DBeaver...\n",
      "split 1 inserido\n",
      "split 2 inserido\n",
      "split 3 inserido\n",
      "split 4 inserido\n",
      "split 5 inserido\n",
      "split 6 inserido\n",
      "split 7 inserido\n",
      "split 8 inserido\n",
      "split 9 inserido\n",
      "split 10 inserido\n",
      "split 11 inserido\n",
      "split 12 inserido\n",
      "split 13 inserido\n",
      "split 14 inserido\n",
      "split 15 inserido\n",
      "split 16 inserido\n",
      "split 17 inserido\n",
      "split 18 inserido\n",
      "split 19 inserido\n",
      "split 20 inserido\n",
      "split 21 inserido\n",
      "split 22 inserido\n",
      "split 23 inserido\n",
      "split 24 inserido\n",
      "split 25 inserido\n",
      "split 26 inserido\n",
      "split 27 inserido\n",
      "split 28 inserido\n",
      "split 29 inserido\n",
      "split 30 inserido\n",
      "split 31 inserido\n",
      "split 32 inserido\n",
      "split 33 inserido\n",
      "split 34 inserido\n",
      "split 35 inserido\n",
      "split 36 inserido\n",
      "split 37 inserido\n",
      "split 38 inserido\n",
      "split 39 inserido\n",
      "split 40 inserido\n",
      "split 41 inserido\n",
      "split 42 inserido\n",
      "split 43 inserido\n",
      "split 44 inserido\n",
      "split 45 inserido\n",
      "split 46 inserido\n",
      "split 47 inserido\n",
      "split 48 inserido\n",
      "split 49 inserido\n",
      "split 50 inserido\n",
      "split 51 inserido\n",
      "split 52 inserido\n",
      "split 53 inserido\n",
      "split 54 inserido\n",
      "split 55 inserido\n",
      "split 56 inserido\n",
      "split 57 inserido\n",
      "split 58 inserido\n",
      "split 59 inserido\n",
      "split 60 inserido\n",
      "split 61 inserido\n",
      "split 62 inserido\n",
      "split 63 inserido\n",
      "split 64 inserido\n",
      "split 65 inserido\n",
      "split 66 inserido\n",
      "split 67 inserido\n",
      "split 68 inserido\n",
      "split 69 inserido\n",
      "split 70 inserido\n",
      "split 71 inserido\n",
      "split 72 inserido\n",
      "split 73 inserido\n",
      "split 74 inserido\n",
      "split 75 inserido\n",
      "split 76 inserido\n",
      "split 77 inserido\n",
      "split 78 inserido\n",
      "split 79 inserido\n",
      "split 80 inserido\n",
      "split 81 inserido\n",
      "split 82 inserido\n",
      "split 83 inserido\n",
      "split 84 inserido\n",
      "split 85 inserido\n",
      "split 86 inserido\n",
      "split 87 inserido\n",
      "split 88 inserido\n",
      "split 89 inserido\n",
      "split 90 inserido\n",
      "split 91 inserido\n",
      "split 92 inserido\n",
      "split 93 inserido\n",
      "split 94 inserido\n",
      "split 95 inserido\n",
      "split 96 inserido\n",
      "split 97 inserido\n",
      "split 98 inserido\n",
      "split 99 inserido\n",
      "split 100 inserido\n"
     ]
    }
   ],
   "source": [
    "# Create bot\n",
    "class Bot():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "              \n",
    "        # Webdriver\n",
    "        options = webdriver.ChromeOptions()\n",
    "        prefs = {\"download.default_directory\": r\"directory\",\n",
    "                \"directory_upgrade\": True}\n",
    "        options.add_experimental_option(\"prefs\", prefs)\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=options)\n",
    "        # Connect DB Beaver\n",
    "        engine = create_engine('postgresql://{}:{}@{}:5432/{}'.format(creds.PGUSER, creds.PGPASSWORD, creds.PGHOST, creds.PGDATABASE) , connect_args={'options': '-csearch_path={}'.format('data_science')})\n",
    "        \n",
    "        # Date and Files\n",
    "        data = datetime.date.today()\n",
    "        mes = int(data.month)-3\n",
    "        option = str(mes)\n",
    "        option = \"0\"+option\n",
    "        option_mes = '//*[@id=\"links-meses\"]/option['+ option +']'\n",
    "        file_name = str(data.year)+option\n",
    "        file = file_name+'.zip'\n",
    "        \n",
    "        # To get the current working directory\n",
    "        directory = os.getcwd()\n",
    "        \n",
    "        # self\n",
    "        self.GetData(driver, directory, data, mes, option, option_mes, file, file_name)\n",
    "        self.ExportData(directory, file_name, engine)\n",
    "\n",
    "        \n",
    "    def GetData(self, driver, directory, data, mes, option, option_mes, file, file_name):\n",
    "        # URL input\n",
    "        driver.get(\"https://www.portaldatransparencia.gov.br/download-de-dados\")\n",
    "        print(\"Acessando Portal da Transparencia...\")\n",
    "    \n",
    "        \n",
    "        # Select benefit\n",
    "        print(\"Selecionando o benefício...\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Benefits list\n",
    "        beneficios = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"btnAbaBeneficios\"]'))).click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Auxilio Brasil\n",
    "        beneficio = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"tableBeneficios\"]/tbody/tr[1]/td[1]/a'))).click()\n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.115 Safari/537.36'}\n",
    "\n",
    "        print (\"Coletando dados...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        # Auxilio Brasil - Last month\n",
    "        auxilio_brasil = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"links-meses\"]/option['+ option +']'))).click()\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            req = Request(driver.current_url, headers = headers)\n",
    "            response = urlopen(req)\n",
    "            #print(response.read())\n",
    "\n",
    "        except HTTPError as e:\n",
    "            print(e.status, e.reason)\n",
    "\n",
    "        except URLError as e:\n",
    "            print(e.reason)\n",
    "        \n",
    "        # Create variable URL\n",
    "        url = driver.current_url\n",
    "        file_url = url+'/'+file_name\n",
    "        request.urlretrieve(file_url , file )\n",
    "        time.sleep(5)\n",
    "        print (\"Download da base...\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Extract file\n",
    "        print(\"Download concluído. Extraindo...\")\n",
    "        zf = ZipFile(file, 'r')\n",
    "        zf.extractall(directory)\n",
    "        zf.close()\n",
    "       \n",
    "    def ExportData(self, directory, file_name, engine):\n",
    "        # Read CSV file\n",
    "        print(\"Reading CSV file...\")\n",
    "        df = pd.read_csv(file_name+\"_AuxilioBrasil.csv\", encoding='iso-8859-1', \n",
    "                                warn_bad_lines=True, error_bad_lines=False, delimiter=';')\n",
    "        \n",
    "        # Export data frame to DBeaver\n",
    "        print(\"Export data frame to DBeaver...\")\n",
    "        splits = np.array_split(df, 100)\n",
    "        i = 0\n",
    "        for split in splits :\n",
    "            i +=1\n",
    "            #print('start split ' + str(i) + ' ' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "            split.to_sql('auxilio_brasil', con=engine, if_exists='append', index=False)\n",
    "            #print('stop split ' + str(i) + ' ' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "            print ('split ' + str(i) + ' inserido')\n",
    "        \n",
    "def main():\n",
    "    My_BOt = Bot()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('env_auxilio': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "959648352dce8d3a3702aa58509ffabae6ceeca4074eb54555fa2cceb6072a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
